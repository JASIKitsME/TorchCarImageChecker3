import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.models import mobilenet_v2, MobileNet_V2_Weights
from tqdm import tqdm
import os
from PIL import Image
import json
import numpy as np

# === –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ===
try:
    import torch_directml
    device = torch_directml.device()
    print("‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è DirectML (AMD GPU)")
except ImportError:
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print("‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CUDA (NVIDIA GPU)")
    else:
        device = torch.device("cpu")
        print("‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")

# –ü—É—Ç–∏
DATA_DIR = os.path.join("data", "data_split")
MODEL_PATH = os.path.join("models", "mobilenet_v2_car_state.pth")
LABELS_FILE = os.path.join(DATA_DIR, "labels.json")  # —Ñ–∞–π–ª —Å –º–µ—Ç–∫–∞–º–∏

# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

# === –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ ===
print(f"DATA_DIR = {DATA_DIR}")
print(f"Train dir = {os.path.join(DATA_DIR, 'train')}")
print(f"Looking for labels.json at: {os.path.join(os.path.dirname(os.path.join(DATA_DIR, 'train')), 'labels.json')}")

# –ü—Ä–æ–≤–µ—Ä–∏–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
label_path_check = os.path.join(os.path.dirname(os.path.join(DATA_DIR, 'train')), 'labels.json')
print(f"File exists? {os.path.exists(label_path_check)}")
import os
import json
from PIL import Image
import torch
from torch.utils.data import Dataset

class CarStateDataset(Dataset):
    def __init__(self, root_dir, transform=None, labels_file="labels.json"):
        self.root_dir = root_dir
        self.transform = transform
        self.image_paths = []
        self.labels = []

        # –ü—É—Ç—å –∫ labels.json ‚Äî –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ, —á—Ç–æ –∏ train/val/test
        base_data_dir = os.path.dirname(root_dir)  # data/data_split
        label_path = os.path.join(base_data_dir, labels_file)

        if not os.path.exists(label_path):
            raise FileNotFoundError(f"–§–∞–π–ª –º–µ—Ç–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω: {label_path}\n"
                                   f"–ó–∞–ø—É—Å—Ç–∏—Ç–µ generate_labels.py –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è labels.json")

        with open(label_path, 'r', encoding='utf-8') as f:
            self.label_map = json.load(f)

        print(f"üîç –ß–∏—Ç–∞–µ–º –º–µ—Ç–∫–∏ –∏–∑: {label_path}")
        print(f"üìÅ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {root_dir}")

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –∫–ª—é—á–∞–º –≤ label_map
        # –ö–ª—é—á–∏ ‚Äî —ç—Ç–æ –ø—É—Ç–∏ —Ç–∏–ø–∞: "train/clean/car_001.jpg"
        # –ù–∞–º –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, train/)
        prefix = os.path.basename(root_dir)  # –Ω–∞–ø—Ä–∏–º–µ—Ä: "train", "val", "test"

        for rel_path, label in self.label_map.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ —ç—Ç–æ—Ç —Ñ–∞–π–ª –∫ —Ç–µ–∫—É—â–µ–º—É –Ω–∞–±–æ—Ä—É (train/val/test)
            if rel_path.startswith(prefix + "/"):  # –Ω–∞–ø—Ä–∏–º–µ—Ä: "train/"
                full_img_path = os.path.join(base_data_dir, rel_path)  # data/data_split/train/clean/car_001.jpg
                if os.path.exists(full_img_path):
                    self.image_paths.append(full_img_path)
                    self.labels.append(label)
                else:
                    print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {full_img_path}")

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ {root_dir}")

        if len(self.image_paths) == 0:
            print("‚ùå –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!")
            print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
            print("  1. –ß—Ç–æ –≤ labels.json –ø—É—Ç–∏ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å 'train/', 'val/', 'test/'")
            print("  2. –ß—Ç–æ —Ñ–∞–π–ª—ã —Ä–µ–∞–ª—å–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –ø–æ —ç—Ç–∏–º –ø—É—Ç—è–º")
            print("  3. –ß—Ç–æ –≤ generate_labels.py –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("RGB")
        label = torch.tensor(self.labels[idx], dtype=torch.float32)

        if self.transform:
            image = self.transform(image)

        return image, label
# –î–∞—Ç–∞—Å–µ—Ç—ã
train_dataset = CarStateDataset(os.path.join(DATA_DIR, "train"), transform=transform)
val_dataset = CarStateDataset(os.path.join(DATA_DIR, "val"), transform=transform)
test_dataset = CarStateDataset(os.path.join(DATA_DIR, "test"), transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# === –ú–æ–¥–µ–ª—å: MobileNetV2 —Å –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º ===
weights = MobileNet_V2_Weights.DEFAULT
model = mobilenet_v2(weights=weights)
model.classifier[1] = nn.Linear(model.last_channel, 2)  # 2 –≤—ã—Ö–æ–¥–∞: clean, damage
model.to(device)

# Loss: MSELoss –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–Ω–µ CrossEntropy!)
criterion = nn.MSELoss()
optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)

# === –û–±—É—á–µ–Ω–∏–µ ===
EPOCHS = 30
for epoch in range(EPOCHS):
    print(f"\nüîÑ –≠–ø–æ—Ö–∞ {epoch+1}/{EPOCHS}")

    # Train
    model.train()
    running_loss = 0.0
    for imgs, labels in tqdm(train_loader, desc="üìò –û–±—É—á–µ–Ω–∏–µ", leave=False):
        imgs, labels = imgs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    train_loss = running_loss / len(train_loader)

    # Validation
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for imgs, labels in tqdm(val_loader, desc="üîç –í–∞–ª–∏–¥–∞—Ü–∏—è", leave=False):
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()

    val_loss = val_loss / len(val_loader)

    print(f"üìä Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")

# === –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ===
model.eval()
test_loss = 0.0
with torch.no_grad():
    for imgs, labels in tqdm(test_loader, desc="üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"):
        imgs, labels = imgs.to(device), labels.to(device)
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        test_loss += loss.item()

test_loss = test_loss / len(test_loader)
print(f"\nüéØ –ò—Ç–æ–≥–æ–≤–∞—è MSE –Ω–∞ —Ç–µ—Å—Ç–µ: {test_loss:.4f}")

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
os.makedirs("models", exist_ok=True)
torch.save(model.state_dict(), MODEL_PATH)
print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_PATH}")